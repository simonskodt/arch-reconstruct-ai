{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4c5d937",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0477cd",
   "metadata": {},
   "source": [
    "## Github"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8b353a",
   "metadata": {},
   "source": [
    "#### Clone a repository based on url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1385bb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Dict, Any\n",
    "from git import Repo, GitCommandError\n",
    "from langchain.tools import tool\n",
    "import os, shutil\n",
    "\n",
    "\n",
    "@tool(\"git_clone\")\n",
    "def git_clone_tool(\n",
    "    repo_url: str,\n",
    "    dest: str,\n",
    "    branch: Optional[str] = None,\n",
    "    overwrite: bool = False,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Clone a Git repository into ./repositories/{dest} using GitPython.\n",
    "\n",
    "    Args:\n",
    "        repo_url: HTTPS or SSH URL of the repository.\n",
    "        dest: Name of the destination folder for the clone inside ./repositories/.\n",
    "        branch: Optional branch to check out.\n",
    "        overwrite: If True, overwrite existing destination folder.\n",
    "    Returns:\n",
    "        A dict with success (bool), dest (str), and error/stdout messages.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Ensure repositories/ root exists\n",
    "        root_dir = os.path.join(os.getcwd(), \"repositories\")\n",
    "        os.makedirs(root_dir, exist_ok=True)\n",
    "\n",
    "        # Full destination path inside repositories/\n",
    "        full_dest = os.path.join(root_dir, dest)\n",
    "\n",
    "        # Handle overwrite\n",
    "        if os.path.exists(full_dest):\n",
    "            if overwrite:\n",
    "                shutil.rmtree(full_dest)\n",
    "            else:\n",
    "                return {\"success\": False, \"error\": f\"Destination {full_dest} already exists.\"}\n",
    "\n",
    "\n",
    "        # Clone options\n",
    "        kwargs = {}\n",
    "        if branch:\n",
    "            kwargs[\"branch\"] = branch\n",
    "            full_dest = f\"{full_dest}/{branch}\"\n",
    "\n",
    "        os.makedirs(full_dest, exist_ok=True)\n",
    "        repo = Repo.clone_from(repo_url, full_dest, **kwargs)\n",
    "\n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"dest\": full_dest,\n",
    "            \"branch\": repo.active_branch.name if not repo.head.is_detached else \"detached\",\n",
    "            \"error\": None,\n",
    "        }\n",
    "    except GitCommandError as e:\n",
    "        return {\"success\": False, \"dest\": dest, \"error\": str(e)}\n",
    "    except Exception as e:\n",
    "        return {\"success\": False, \"dest\": dest, \"error\": str(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f380f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='Can you clone the following github repository: https://github.com/ThomasITU/Agentic-AI, you can overwrite it if there already is a clone by setting the flag to True', additional_kwargs={}, response_metadata={}, id='48e5147d-ebef-4374-94da-6980b718223d'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_b9gmuwMMovfwAbSzfNgDoz6A', 'function': {'arguments': '{\"repo_url\":\"https://github.com/ThomasITU/Agentic-AI\",\"dest\":\"Agentic-AI\",\"branch\":null,\"depth\":null,\"overwrite\":true}', 'name': 'git_clone'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 246, 'prompt_tokens': 300, 'total_tokens': 546, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 192, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CLcNNMZPKU7yXYoEID17WyehFvpMD', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--d1f05cc3-9ec9-41d3-bc88-ebdcf3eb3782-0', tool_calls=[{'name': 'git_clone', 'args': {'repo_url': 'https://github.com/ThomasITU/Agentic-AI', 'dest': 'Agentic-AI', 'branch': None, 'depth': None, 'overwrite': True}, 'id': 'call_b9gmuwMMovfwAbSzfNgDoz6A', 'type': 'tool_call'}], usage_metadata={'input_tokens': 300, 'output_tokens': 246, 'total_tokens': 546, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 192}}), ToolMessage(content='{\"success\": true, \"dest\": \"/Users/thomas/Desktop/arch-reconstruct-ai/experiments/tool-calling/repositories/Agentic-AI\", \"branch\": \"main\", \"error\": null}', name='git_clone', id='0584546c-6266-4006-a6de-4ac6d2b98717', tool_call_id='call_b9gmuwMMovfwAbSzfNgDoz6A'), AIMessage(content=\"I've cloned the repository Agentic-AI from the provided URL into the following location:\\n- /Users/thomas/Desktop/arch-reconstruct-ai/experiments/tool-calling/repositories/Agentic-AI\\n\\nThe clone was successful. If you'd like me to list the contents or install dependencies, just say the word.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 67, 'prompt_tokens': 402, 'total_tokens': 469, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CLcNXlkHgGOotxKW50PHPZVWDZitu', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--15be91ae-80b9-497b-aab9-2624e95de72f-0', usage_metadata={'input_tokens': 402, 'output_tokens': 67, 'total_tokens': 469, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "agent = create_agent(\n",
    "    \"openai:gpt-5-nano\",\n",
    "    tools=[git_clone_tool],\n",
    "    prompt=\"Act as an assistant. Use the git_clone_tool to download a repository.\",\n",
    ")\n",
    "\n",
    "result = agent.invoke({\"messages\": [HumanMessage(\"Can you clone the following github repository: https://github.com/simonskodt/arch-reconstruct-ai, feel free to overwrite if a clone already exists, \")]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff4be9f",
   "metadata": {},
   "source": [
    "#### Add Github MCP server based on url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "059673ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'experiments'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict, Any\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tool\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexperiments\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmcp_client_factory\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_mcp_config, save_mcp_config, create_mcp_client_from_config\n\u001b[32m      5\u001b[39m \u001b[38;5;129m@tool\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33madd_mcp_server\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34madd_mcp_server_tool\u001b[39m(\n\u001b[32m      7\u001b[39m     name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m      8\u001b[39m     url: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m      9\u001b[39m     transport: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mstreamable_http\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     10\u001b[39m ) -> Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m     11\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[33;03m    Add a new MCP server to the configuration.\u001b[39;00m\n\u001b[32m     13\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     23\u001b[39m \u001b[33;03m        a new agent or tool instance has to be  \u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'experiments'"
     ]
    }
   ],
   "source": [
    "from typing import Dict, Any\n",
    "from langchain.tools import tool\n",
    "from experiments.utils.mcp_client_factory import load_mcp_config, save_mcp_config, create_mcp_client_from_config\n",
    "\n",
    "@tool(\"add_mcp_server\")\n",
    "def add_mcp_server_tool(\n",
    "    name: str,\n",
    "    url: str,\n",
    "    transport: str = \"streamable_http\",\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Add a new MCP server to the configuration.\n",
    "    \n",
    "    Args:\n",
    "        name: Name identifier for the MCP server\n",
    "        url: URL of the MCP server\n",
    "        transport: Transport type (default: \"streamable_http\")\n",
    "    Returns:\n",
    "        Dict with success status and current config\n",
    "\n",
    "    Note: \n",
    "        MCP tools accessed via clients are not hot reloaded or dynamically  updated,\n",
    "        a new agent or tool instance has to be  \n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load existing config\n",
    "        config = load_mcp_config()\n",
    "        \n",
    "        # Add new server\n",
    "        config[name] = {\n",
    "            \"url\": url,\n",
    "            \"transport\": transport\n",
    "        }\n",
    "    \n",
    "        save_mcp_config(config)\n",
    "        \n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"message\": f\"Added MCP server '{name}'\",\n",
    "            \"config\": config\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"error\": str(e),\n",
    "            \"config\": {}\n",
    "        }\n",
    "    \n",
    "@tool(\"add_github_repository_as_mcp_server\")\n",
    "def add_github_repository_as_mcp_tool(repo_url: str, server_name: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Add a GitHub repository as an MCP server using gitmcp.io.\n",
    "    \n",
    "    Args:\n",
    "        repo_url: GitHub repository URL (e.g., https://github.com/owner/repo)\n",
    "        server_name: Name identifier for the MCP server\n",
    "    Returns:\n",
    "        Dict with success status and current config\n",
    "    \"\"\"\n",
    "    # Extract the repository path from the GitHub URL\n",
    "    if \"github.com/\" in repo_url:\n",
    "        # Extract everything after github.com/\n",
    "        repo_path = repo_url.split(\"github.com/\", 1)[1]\n",
    "        # Remove .git suffix if present\n",
    "        if repo_path.endswith(\".git\"):\n",
    "            repo_path = repo_path[:-4]\n",
    "        gitmcp_url = f\"https://gitmcp.io/{repo_path}\"\n",
    "    else:\n",
    "        raise ValueError(\"Invalid GitHub repository URL\")\n",
    "    \n",
    "    tool_input = {\n",
    "        \"name\": server_name,\n",
    "        \"url\": gitmcp_url,\n",
    "    }\n",
    "\n",
    "    return add_mcp_server_tool.invoke(tool_input)\n",
    "\n",
    "    \n",
    "\n",
    "@tool(\"remove_mcp_server\")\n",
    "def remove_mcp_server_tool(\n",
    "    name: str,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Remove an MCP server from the configuration.\n",
    "    \n",
    "    Args:\n",
    "        name: Name identifier of the MCP server to remove\n",
    "    Returns:\n",
    "        Dict with success status and current config\n",
    "\n",
    "    Note: \n",
    "        MCP tools accessed via clients are not hot reloaded or dynamically  updated,\n",
    "        a new agent or tool instance has to be \n",
    "    \"\"\"\n",
    "    try:\n",
    "        config = load_mcp_config()\n",
    "        \n",
    "        if name not in config:\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": f\"MCP server '{name}' not found\",\n",
    "                \"config\": config\n",
    "            }\n",
    "        \n",
    "        del config[name]\n",
    "        save_mcp_config(config)\n",
    "        \n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"message\": f\"Removed MCP server '{name}'\",\n",
    "            \"config\": config\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"error\": str(e),\n",
    "            \"config\": {}\n",
    "        }\n",
    "\n",
    "@tool(\"list_mcp_servers\")\n",
    "def list_mcp_servers() -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    List all configured MCP servers.\n",
    "    \n",
    "    Returns:\n",
    "        Dict with success status and list of servers\n",
    "    \"\"\"\n",
    "    try:\n",
    "        config = load_mcp_config()\n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"servers\": list(config.keys()),\n",
    "            \"config\": config\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"error\": str(e),\n",
    "            \"config\": {}\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9af334f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_iqNmvENZzhZ7Wh3kntQPXqkJ', 'function': {'arguments': '{\"repo_url\":\"https://github.com/simonskodt/arch-reconstruct-ai\",\"dest\":\"arch-reconstruct-ai\",\"branch\":null,\"overwrite\":false}', 'name': 'git_clone'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 308, 'prompt_tokens': 511, 'total_tokens': 819, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 256, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CLo4ayGmdBLSAkgAUugCxyrMtnlJ7', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--277e2183-d669-49fd-844c-d2a1f3f364b6-0', tool_calls=[{'name': 'git_clone', 'args': {'repo_url': 'https://github.com/simonskodt/arch-reconstruct-ai', 'dest': 'arch-reconstruct-ai', 'branch': None, 'overwrite': False}, 'id': 'call_iqNmvENZzhZ7Wh3kntQPXqkJ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 511, 'output_tokens': 308, 'total_tokens': 819, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 256}})]}}\n",
      "{'tools': {'messages': [ToolMessage(content='{\"success\": true, \"dest\": \"/Users/thomas/Desktop/arch-reconstruct-ai/experiments/tool-calling/repositories/arch-reconstruct-ai\", \"branch\": \"main\", \"error\": null}', name='git_clone', id='850b5a5c-b43c-4d8d-afa8-0fa1209ba2ec', tool_call_id='call_iqNmvENZzhZ7Wh3kntQPXqkJ')]}}\n",
      "{'agent': {'messages': [AIMessage(content='Cloning complete.\\n\\n- Destination: /Users/thomas/Desktop/arch-reconstruct-ai/experiments/tool-calling/repositories/arch-reconstruct-ai\\n- Branch checked out: main\\n- Status: success (no errors)\\n\\nWould you like me to do any of the following?\\n- List the top-level files and folders to get an overview\\n- Open and summarize the README and/or important docs\\n- Set up a virtual environment and install dependencies\\n- Run a quick check or a sample script from the repo\\n- Inspect specific parts (e.g., notebooks, experiments, or modules)\\n\\nTell me what you want to explore next.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 905, 'prompt_tokens': 611, 'total_tokens': 1516, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 768, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CLo4erMPAnvcfbisGZ7Ny38HAinfV', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--e90b2989-8340-410d-b832-9602c985684f-0', usage_metadata={'input_tokens': 611, 'output_tokens': 905, 'total_tokens': 1516, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 768}})]}}\n",
      "{'messages': [HumanMessage(content='Can you list the MCP servers available', additional_kwargs={}, response_metadata={}, id='69a97777-868b-45c7-adc4-1c65e5b0d72a'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_lckmEivf6jSR4N2V2m5J54ez', 'function': {'arguments': '{}', 'name': 'list_mcp_servers'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 85, 'prompt_tokens': 497, 'total_tokens': 582, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 64, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CLo4o0yiUHThct7kO0xUPvkTO4gml', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--b4046b50-80f7-491c-9a3f-2b4b8edc2b81-0', tool_calls=[{'name': 'list_mcp_servers', 'args': {}, 'id': 'call_lckmEivf6jSR4N2V2m5J54ez', 'type': 'tool_call'}], usage_metadata={'input_tokens': 497, 'output_tokens': 85, 'total_tokens': 582, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 64}}), ToolMessage(content='{\"success\": true, \"servers\": [], \"config\": {}}', name='list_mcp_servers', id='87874eba-0846-46ba-b618-8abf1e1cb360', tool_call_id='call_lckmEivf6jSR4N2V2m5J54ez'), AIMessage(content='Currently there are no MCP servers configured.\\n\\nWhat would you like to do next? Options:\\n- Add a new MCP server: provide name and URL (and optional transport; default is streamable_http)\\n  - Example: add_mcp_server with { name: \"my-server\", url: \"https://example.com/mcp\" }\\n- Link a GitHub repository as an MCP server: provide repo_url and server_name\\n  - Example: add_github_repository_as_mcp_server with { repo_url: \"https://github.com/owner/repo\", server_name: \"repo-mcp\" }\\n- After adding, I can list again to confirm.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 461, 'prompt_tokens': 539, 'total_tokens': 1000, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 320, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CLo4uGahDChxbonNdp71CKUhZQQiI', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--e31ef77c-796b-41cb-b5f3-0c7330ce52cb-0', usage_metadata={'input_tokens': 539, 'output_tokens': 461, 'total_tokens': 1000, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 320}})]}\n",
      "{'messages': [HumanMessage(content='Can you take the following github repository: https://github.com/simonskodt/arch-reconstruct-ai, and make it into a MCP server', additional_kwargs={}, response_metadata={}, id='4fc9b395-0112-4f98-b252-fb5ea7bcf6bd'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_agCCfhyUkMoE5nYNloudJWdR', 'function': {'arguments': '{\"repo_url\":\"https://github.com/simonskodt/arch-reconstruct-ai\",\"server_name\":\"arch-reconstruct-ai-mcp\"}', 'name': 'add_github_repository_as_mcp_server'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 949, 'prompt_tokens': 520, 'total_tokens': 1469, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 896, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CLo4yYhnw5r3O7R8yblHiHJBdBM0M', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--d2179dfb-2a9e-4a76-955e-5ab9cc88cc13-0', tool_calls=[{'name': 'add_github_repository_as_mcp_server', 'args': {'repo_url': 'https://github.com/simonskodt/arch-reconstruct-ai', 'server_name': 'arch-reconstruct-ai-mcp'}, 'id': 'call_agCCfhyUkMoE5nYNloudJWdR', 'type': 'tool_call'}], usage_metadata={'input_tokens': 520, 'output_tokens': 949, 'total_tokens': 1469, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 896}}), ToolMessage(content='{\"success\": true, \"message\": \"Added MCP server \\'arch-reconstruct-ai-mcp\\'\", \"config\": {\"arch-reconstruct-ai-mcp\": {\"url\": \"https://gitmcp.io/simonskodt/arch-reconstruct-ai\", \"transport\": \"streamable_http\"}}}', name='add_github_repository_as_mcp_server', id='3a7289fd-15ec-461d-a350-2768781edb85', tool_call_id='call_agCCfhyUkMoE5nYNloudJWdR'), AIMessage(content='All set. I’ve turned the repository into an MCP server.\\n\\nWhat I did\\n- Added MCP server for the repo: https://github.com/simonskodt/arch-reconstruct-ai\\n- Server name: arch-reconstruct-ai-mcp\\n- MCP URL: https://gitmcp.io/simonskodt/arch-reconstruct-ai\\n- Transport: streamable_http\\n\\nCurrent config (high level)\\n- arch-reconstruct-ai-mcp\\n  - url: https://gitmcp.io/simonskodt/arch-reconstruct-ai\\n  - transport: streamable_http\\n\\nNext steps (optional)\\n- Verify connectivity: open https://gitmcp.io/simonskodt/arch-reconstruct-ai in a browser or use an MCP client to test.\\n- List all configured MCP servers if you want to see others: I can run a list for you.\\n- Clone the repository locally for testing in the MCP environment:\\n  - If you want, I can clone it into ./repositories/arch-reconstruct-ai using GitPython.\\n- If you’d like a different server name or a different transport, I can adjust and reconfigure.\\n\\nWould you like me to clone the repository into the environment for testing, or list existing MCP servers to confirm the setup?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1292, 'prompt_tokens': 645, 'total_tokens': 1937, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 1024, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CLo55OsCNzltFyQF7DYQdiCV3QGD9', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--6cfc6363-8b43-4c9f-bafe-3e59e2c59ae3-0', usage_metadata={'input_tokens': 645, 'output_tokens': 1292, 'total_tokens': 1937, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 1024}})]}\n",
      "add_github_repository_as_mcp_server\n",
      "add_mcp_server\n",
      "remove_mcp_server\n",
      "list_mcp_servers\n",
      "git_clone\n",
      "fetch_arch_reconstruct_docs\n",
      "search_arch_docs\n",
      "search_arch_code\n",
      "fetch_generic_url_content\n",
      "{'messages': [HumanMessage(content='Can you list the MCP servers available', additional_kwargs={}, response_metadata={}, id='b6f5c0db-4a60-4bf5-b240-870f234526c5'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_KpYqAsQjbp0NUCMInAWasUUF', 'function': {'arguments': '{}', 'name': 'list_mcp_servers'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 149, 'prompt_tokens': 748, 'total_tokens': 897, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 128, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CLo5HZkZjjRBgAtCg9bxJZAGyKfei', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--5874247b-332c-41d3-a0dc-8ea2dd6d68f8-0', tool_calls=[{'name': 'list_mcp_servers', 'args': {}, 'id': 'call_KpYqAsQjbp0NUCMInAWasUUF', 'type': 'tool_call'}], usage_metadata={'input_tokens': 748, 'output_tokens': 149, 'total_tokens': 897, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 128}}), ToolMessage(content='{\"success\": true, \"servers\": [\"arch-reconstruct-ai-mcp\"], \"config\": {\"arch-reconstruct-ai-mcp\": {\"url\": \"https://gitmcp.io/simonskodt/arch-reconstruct-ai\", \"transport\": \"streamable_http\"}}}', name='list_mcp_servers', id='2ff68457-f1b6-41fe-84c3-7132762b2921', tool_call_id='call_KpYqAsQjbp0NUCMInAWasUUF'), AIMessage(content='Here are the available MCP servers:\\n\\n- arch-reconstruct-ai-mcp\\n  - URL: https://gitmcp.io/simonskodt/arch-reconstruct-ai\\n  - Transport: streamable_http\\n\\nCurrent configuration: arch-reconstruct-ai-mcp is configured with the above URL and transport.\\n\\nWould you like to add more MCP servers or modify this configuration? I can help with adding a new server or linking a GitHub repository as an MCP server.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 487, 'prompt_tokens': 833, 'total_tokens': 1320, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 384, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CLo5dXaLpwcvhHX51AEei77YtwD2u', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--3574429a-140b-4814-9421-8f36875880f4-0', usage_metadata={'input_tokens': 833, 'output_tokens': 487, 'total_tokens': 1320, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 384}})]}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "import sys\n",
    "import os\n",
    "# Add the parent directory to sys.path so 'experiments' can be imported\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..', '..')))\n",
    "from experiments.utils.agent_factory import create_agent_with_valid_tools\n",
    "\n",
    "tools = [add_github_repository_as_mcp_tool, add_mcp_server_tool, remove_mcp_server_tool, list_mcp_servers, git_clone_tool]\n",
    "\n",
    "agent = create_agent_with_valid_tools(\n",
    "    \"openai:gpt-5-nano\",\n",
    "    tools=tools,\n",
    "    prompt=\"\"\"Act as an assistant.\n",
    "                When using tools:\n",
    "                - Use tools if relevant before answering.\n",
    "            \"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "stream = agent.astream({\"messages\": [HumanMessage(\"Can you clone the github repository: https://github.com/simonskodt/arch-reconstruct-ai\")]})\n",
    "async for chunk in stream:\n",
    "    print(chunk)\n",
    "\n",
    "\n",
    "result = await agent.ainvoke({\"messages\": [HumanMessage(\"Can you list the MCP servers available\")]})\n",
    "print(result)\n",
    "\n",
    "result = await agent.ainvoke({\"messages\": [HumanMessage(\"Can you take the following github repository: https://github.com/simonskodt/arch-reconstruct-ai, and make it into a MCP server\")]})\n",
    "print(result)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "client = create_mcp_client_from_config()\n",
    "mcp_tools = await client.get_tools() \n",
    "tools += mcp_tools\n",
    "\n",
    "[print(tool.name) for tool in tools]\n",
    "\n",
    "agent = create_agent_with_valid_tools(\n",
    "    \"openai:gpt-5-nano\",\n",
    "    tools=tools, # Tools cannot be dynamically  or hot reloaded?, agent has to be recreated  \n",
    "    prompt=\"\"\"Act as an assistant.\n",
    "                When using tools:\n",
    "                - Use tools if relevant before answering.\n",
    "            \"\"\"\n",
    ")\n",
    "result = await agent.ainvoke({\"messages\": [HumanMessage(\"Can you list the MCP servers available\")]})\n",
    "print(result)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arch-reconstruct-ai (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
