{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4c5d937",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0477cd",
   "metadata": {},
   "source": [
    "## Github"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8b353a",
   "metadata": {},
   "source": [
    "#### Clone a repository based on url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9008e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.ArchLensConfig object at 0x11023e3c0>\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional, Dict, Any, List\n",
    "from logging import Handler\n",
    "\n",
    "class ArchLensConfig:\n",
    "  def __init__(\n",
    "    self,\n",
    "    name: str,\n",
    "    rootFolder: str,\n",
    "    views: Dict[str, Dict[str, List[Dict[str, Any]]]]\n",
    "  ):\n",
    "    self.name = name\n",
    "    self.rootFolder = rootFolder\n",
    "    self.saveLocation = \"./diagrams/\"\n",
    "    self.views = views\n",
    "\n",
    "  @staticmethod\n",
    "  def from_dict(data: Dict[str, Any]) -> 'ArchLensConfig':\n",
    "    github = data['github']\n",
    "    views = {}\n",
    "    for view_name, view_data in data['views'].items():\n",
    "      views[view_name] = view_data['packages']\n",
    "    return ArchLensConfig(\n",
    "      schema=data.get('$schema', ''),\n",
    "      name=data.get('name', ''),\n",
    "      root_folder=data.get('rootFolder', ''),\n",
    "      github_url=github.get('url', ''),\n",
    "      github_branch=github.get('branch', ''),\n",
    "      save_location=data.get('saveLocation', ''),\n",
    "      views=views\n",
    "    )\n",
    "  \n",
    "#create Archlensobject\n",
    "viewsJson = {\"top-level-view-depth-1\": {\n",
    "      \"packages\": [\n",
    "        {\n",
    "          \"path\": \"*\",\n",
    "          \"depth\": 1\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    \"top-level-view-depth-2\": {\n",
    "      \"packages\": [\n",
    "        {\n",
    "          \"path\": \"*\",\n",
    "          \"depth\": 2\n",
    "        }\n",
    "      ]\n",
    "    }}\n",
    "\n",
    "archlensObject = ArchLensConfig(name='testing' ,rootFolder='zeeguu', views=viewsJson)\n",
    "\n",
    "print(archlensObject)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1385bb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Dict, Any\n",
    "from git import Repo, GitCommandError\n",
    "from langchain.tools import tool\n",
    "import os, shutil\n",
    "\n",
    "\n",
    "@tool(\"git_clone\")\n",
    "def git_clone_tool(\n",
    "    repo_url: str,\n",
    "    dest: str,\n",
    "    branch: Optional[str] = None,\n",
    "    overwrite: bool = False,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Clone a Git repository into ./repositories/{dest} using GitPython.\n",
    "\n",
    "    Args:\n",
    "        repo_url: HTTPS or SSH URL of the repository.\n",
    "        dest: Name of the destination folder for the clone inside ./repositories/.\n",
    "        branch: Optional branch to check out.\n",
    "        overwrite: If True, overwrite existing destination folder.\n",
    "    Returns:\n",
    "        A dict with success (bool), dest (str), and error/stdout messages.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Ensure repositories/ root exists\n",
    "        root_dir = os.path.join(os.getcwd(), \"repositories\")\n",
    "        os.makedirs(root_dir, exist_ok=True)\n",
    "\n",
    "        # Full destination path inside repositories/\n",
    "        full_dest = os.path.join(root_dir, dest)\n",
    "\n",
    "        # Handle overwrite\n",
    "        if os.path.exists(full_dest):\n",
    "            if overwrite:\n",
    "                shutil.rmtree(full_dest)\n",
    "            else:\n",
    "                return {\"success\": False, \"error\": f\"Destination {full_dest} already exists.\"}\n",
    "\n",
    "\n",
    "        # Clone options\n",
    "        kwargs = {}\n",
    "        if branch:\n",
    "            kwargs[\"branch\"] = branch\n",
    "            full_dest = f\"{full_dest}/{branch}\"\n",
    "\n",
    "        os.makedirs(full_dest, exist_ok=True)\n",
    "        repo = Repo.clone_from(repo_url, full_dest, **kwargs)\n",
    "\n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"dest\": full_dest,\n",
    "            \"branch\": repo.active_branch.name if not repo.head.is_detached else \"detached\",\n",
    "            \"error\": None,\n",
    "        }\n",
    "    except GitCommandError as e:\n",
    "        return {\"success\": False, \"dest\": dest, \"error\": str(e)}\n",
    "    except Exception as e:\n",
    "        return {\"success\": False, \"dest\": dest, \"error\": str(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75555da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository name: api\n",
      "Repository name: api\n",
      "analyzing /Users/nikolajworsoelarsen/Desktop/CSKandidat/Thesis/arch-reconstruct-ai/experiments/tool-calling/repositories/api/zeeguu\n",
      "analyzing /Users/nikolajworsoelarsen/Desktop/CSKandidat/Thesis/arch-reconstruct-ai/experiments/tool-calling/repositories/api/zeeguu/core\n",
      "analyzing /Users/nikolajworsoelarsen/Desktop/CSKandidat/Thesis/arch-reconstruct-ai/experiments/tool-calling/repositories/api/zeeguu/core/user_activity_hooks\n",
      "analyzing /Users/nikolajworsoelarsen/Desktop/CSKandidat/Thesis/arch-reconstruct-ai/experiments/tool-calling/repositories/api/zeeguu/core/account_management\n",
      "analyzing /Users/nikolajworsoelarsen/Desktop/CSKandidat/Thesis/arch-reconstruct-ai/experiments/tool-calling/repositories/api/zeeguu/core/word_filter\n",
      "analyzing /Users/nikolajworsoelarsen/Desktop/CSKandidat/Thesis/arch-reconstruct-ai/experiments/tool-calling/repositories/api/zeeguu/core/word_scheduling\n",
      "analyzing /Users/nikolajworsoelarsen/Desktop/CSKandidat/Thesis/arch-reconstruct-ai/experiments/tool-calling/repositories/api/zeeguu/core/word_scheduling/basicSR\n",
      "analyzing /Users/nikolajworsoelarsen/Desktop/CSKandidat/Thesis/arch-reconstruct-ai/experiments/tool-calling/repositories/api/zeeguu/core/test\n",
      "analyzing /Users/nikolajworsoelarsen/Desktop/CSKandidat/Thesis/arch-reconstruct-ai/experiments/tool-calling/repositories/api/zeeguu/core/test/rules\n",
      "analyzing /Users/nikolajworsoelarsen/Desktop/CSKandidat/Thesis/arch-reconstruct-ai/experiments/tool-calling/repositories/api/zeeguu/core/test/tests_difficulty_estimator_strategies\n",
      "analyzing /Users/nikolajworsoelarsen/Desktop/CSKandidat/Thesis/arch-reconstruct-ai/experiments/tool-calling/repositories/api/zeeguu/core/behavioral_modeling\n",
      "analyzing /Users/nikolajworsoelarsen/Desktop/CSKandidat/Thesis/arch-reconstruct-ai/experiments/tool-calling/repositories/api/zeeguu/core/util\n",
      "analyzing /Users/nikolajworsoelarsen/Desktop/CSKandidat/Thesis/arch-reconstruct-ai/experiments/tool-calling/repositories/api/zeeguu/core/elastic\n",
      "analyzing /Users/nikolajworsoelarsen/Desktop/CSKandidat/Thesis/arch-reconstruct-ai/experiments/tool-calling/repositories/api/zeeguu/core/word_stats\n",
      "analyzing /Users/nikolajworsoelarsen/Desktop/CSKandidat/Thesis/arch-reconstruct-ai/experiments/tool-calling/repositories/api/zeeguu/core/audio_lessons\n",
      "analyzing /Users/nikolajworsoelarsen/Desktop/CSKandidat/Thesis/arch-reconstruct-ai/experiments/tool-calling/repositories/api/zeeguu/core/content_recommender\n",
      "analyzing /Users/nikolajworsoelarsen/Desktop/CSKandidat/Thesis/arch-reconstruct-ai/experiments/tool-calling/repositories/api/zeeguu/core/content_quality\n",
      "analyzing /Users/nikolajworsoelarsen/Desktop/CSKandidat/Thesis/arch-reconstruct-ai/experiments/tool-calling/repositories/api/zeeguu/core/content_retriever\n",
      "analyzing /Users/nikolajworsoelarsen/Desktop/CSKandidat/Thesis/arch-reconstruct-ai/experiments/tool-calling/repositories/api/zeeguu/core/language\n",
      "analyzing /Users/nikolajworsoelarsen/Desktop/CSKandidat/Thesis/arch-reconstruct-ai/experiments/tool-calling/repositories/api/zeeguu/core/language/strategies\n",
      "analyzing /Users/nikolajworsoelarsen/Desktop/CSKandidat/Thesis/arch-reconstruct-ai/experiments/tool-calling/repositories/api/zeeguu/core/tokenization\n",
      "analyzing /Users/nikolajworsoelarsen/Desktop/CSKandidat/Thesis/arch-reconstruct-ai/experiments/tool-calling/repositories/api/zeeguu/core/semantic_vector_api\n",
      "analyzing /Users/nikolajworsoelarsen/Desktop/CSKandidat/Thesis/arch-reconstruct-ai/experiments/tool-calling/repositories/api/zeeguu/core/exercises\n",
      "analyzing /Users/nikolajworsoelarsen/Desktop/CSKandidat/Thesis/arch-reconstruct-ai/experiments/tool-calling/repositories/api/zeeguu/core/user_statistics\n",
      "analyzing /Users/nikolajworsoelarsen/Desktop/CSKandidat/Thesis/arch-reconstruct-ai/experiments/tool-calling/repositories/api/zeeguu/core/model\n",
      "analyzing /Users/nikolajworsoelarsen/Desktop/CSKandidat/Thesis/arch-reconstruct-ai/experiments/tool-calling/repositories/api/zeeguu/core/content_cleaning\n",
      "analyzing /Users/nikolajworsoelarsen/Desktop/CSKandidat/Thesis/arch-reconstruct-ai/experiments/tool-calling/repositories/api/zeeguu/core/crowd_translations\n",
      "analyzing /Users/nikolajworsoelarsen/Desktop/CSKandidat/Thesis/arch-reconstruct-ai/experiments/tool-calling/repositories/api/zeeguu/core/nlp_pipeline\n",
      "analyzing /Users/nikolajworsoelarsen/Desktop/CSKandidat/Thesis/arch-reconstruct-ai/experiments/tool-calling/repositories/api/zeeguu/core/bookmark_quality\n",
      "analyzing /Users/nikolajworsoelarsen/Desktop/CSKandidat/Thesis/arch-reconstruct-ai/experiments/tool-calling/repositories/api/zeeguu/core/semantic_search\n",
      "analyzing /Users/nikolajworsoelarsen/Desktop/CSKandidat/Thesis/arch-reconstruct-ai/experiments/tool-calling/repositories/api/zeeguu/core/ml_models\n",
      "analyzing /Users/nikolajworsoelarsen/Desktop/CSKandidat/Thesis/arch-reconstruct-ai/experiments/tool-calling/repositories/api/zeeguu/core/emailer\n",
      "analyzing /Users/nikolajworsoelarsen/Desktop/CSKandidat/Thesis/arch-reconstruct-ai/experiments/tool-calling/repositories/api/zeeguu/core/feed_handler\n",
      "analyzing /Users/nikolajworsoelarsen/Desktop/CSKandidat/Thesis/arch-reconstruct-ai/experiments/tool-calling/repositories/api/zeeguu/core/llm_services\n",
      "analyzing /Users/nikolajworsoelarsen/Desktop/CSKandidat/Thesis/arch-reconstruct-ai/experiments/tool-calling/repositories/api/zeeguu/core/llm_services/prompts\n",
      "analyzing /Users/nikolajworsoelarsen/Desktop/CSKandidat/Thesis/arch-reconstruct-ai/experiments/tool-calling/repositories/api/zeeguu/core/sql\n",
      "analyzing /Users/nikolajworsoelarsen/Desktop/CSKandidat/Thesis/arch-reconstruct-ai/experiments/tool-calling/repositories/api/zeeguu/core/sql/learner\n",
      "analyzing /Users/nikolajworsoelarsen/Desktop/CSKandidat/Thesis/arch-reconstruct-ai/experiments/tool-calling/repositories/api/zeeguu/core/sql/teacher\n",
      "analyzing /Users/nikolajworsoelarsen/Desktop/CSKandidat/Thesis/arch-reconstruct-ai/experiments/tool-calling/repositories/api/zeeguu/config\n",
      "analyzing /Users/nikolajworsoelarsen/Desktop/CSKandidat/Thesis/arch-reconstruct-ai/experiments/tool-calling/repositories/api/zeeguu/api\n",
      "analyzing /Users/nikolajworsoelarsen/Desktop/CSKandidat/Thesis/arch-reconstruct-ai/experiments/tool-calling/repositories/api/zeeguu/api/endpoints\n",
      "analyzing /Users/nikolajworsoelarsen/Desktop/CSKandidat/Thesis/arch-reconstruct-ai/experiments/tool-calling/repositories/api/zeeguu/api/endpoints/teacher_dashboard\n",
      "analyzing /Users/nikolajworsoelarsen/Desktop/CSKandidat/Thesis/arch-reconstruct-ai/experiments/tool-calling/repositories/api/zeeguu/api/endpoints/helpers\n",
      "analyzing /Users/nikolajworsoelarsen/Desktop/CSKandidat/Thesis/arch-reconstruct-ai/experiments/tool-calling/repositories/api/zeeguu/api/utils\n",
      "analyzing /Users/nikolajworsoelarsen/Desktop/CSKandidat/Thesis/arch-reconstruct-ai/experiments/tool-calling/repositories/api/zeeguu/cl\n",
      "analyzing /Users/nikolajworsoelarsen/Desktop/CSKandidat/Thesis/arch-reconstruct-ai/experiments/tool-calling/repositories/api/zeeguu/logging\n",
      "[{'filename': './diagrams/testing-top-level-view-depth-1', 'gen_success': True}]\n",
      "[{'filename': './diagrams/testing-top-level-view-depth-2', 'gen_success': True}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Ran archLens'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "@tool('init_archLens')\n",
    "def init_archLens(repo_url: str):\n",
    "    \"\"\"\"If you have cloned the arch-reconstruct-ai repository, initialize archLens.\"\"\"\n",
    "\n",
    "    repo_name = repo_url.rstrip('/').split('/')[-1]\n",
    "    if repo_name.endswith('.git'):\n",
    "        repo_name = repo_name[:-4]\n",
    "    print(f\"Repository name: {repo_name}\")\n",
    "\n",
    "    repo_path = \"/Users/nikolajworsoelarsen/Desktop/CSKandidat/Thesis/arch-reconstruct-ai/experiments/tool-calling/repositories/\"+repo_name\n",
    "    os.chdir(repo_path)\n",
    "\n",
    "    if os.path.exists(\"archlens.json\"):\n",
    "        print(\"archlens.json already exists, skipping initialization.\")\n",
    "    else:\n",
    "        os.system(\"archlens init\")\n",
    "\n",
    "    return \"Initialized archLens\"\n",
    "\n",
    "@tool('run_archLens')\n",
    "def run_archLens(repo_url: str):\n",
    "    \"\"\"\"Run archLens on the cloned repository.\"\"\"\n",
    "\n",
    "    repo_name = repo_url.rstrip('/').split('/')[-1]\n",
    "    if repo_name.endswith('.git'):\n",
    "        repo_name = repo_name[:-4]\n",
    "    print(f\"Repository name: {repo_name}\")\n",
    "    \n",
    "    repo_path = \"/Users/nikolajworsoelarsen/Desktop/CSKandidat/Thesis/arch-reconstruct-ai/experiments/tool-calling/repositories/\"+repo_name\n",
    "    os.chdir(repo_path)\n",
    "\n",
    "    if not os.path.exists(\"archlens.json\"):\n",
    "        return \"archlens.json does not exist. Please run init_archLens first.\"\n",
    "\n",
    "    os.system(f\"archlens render\")\n",
    "\n",
    "    return \"Ran archLens\"\n",
    "\n",
    "\n",
    "@tool('read_archLens_config_file')\n",
    "def read_archLens_config_file(repo_url: str):\n",
    "    \"\"\"\"Reads the content of the archlens.json file.\"\"\"\n",
    "\n",
    "    repo_name = repo_url.rstrip('/').split('/')[-1]\n",
    "    if repo_name.endswith('.git'):\n",
    "        repo_name = repo_name[:-4]\n",
    "    print(f\"Repository name: {repo_name}\")\n",
    "\n",
    "    repo_path = \"/Users/nikolajworsoelarsen/Desktop/CSKandidat/Thesis/arch-reconstruct-ai/experiments/tool-calling/repositories/\"+repo_name\n",
    "    os.chdir(repo_path)\n",
    "\n",
    "    config_path = \"archlens.json\"\n",
    "    if not os.path.exists(config_path):\n",
    "        return \"archlens.json does not exist. Please run init_archLens first.\"\n",
    "    \n",
    "    with open('archlens.json', 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    print(json.dumps(data, indent=4))\n",
    "\n",
    "    return \"Read config file\"\n",
    "\n",
    "\n",
    "@tool('write_archLens_config_file')\n",
    "def write_archLens_config_file(repo_url: str, arch: ArchLensConfig):\n",
    "    \"\"\"\"Writes content to the archlens.json file.\n",
    "        args: \n",
    "    \"\"\"\n",
    "    repo_name = repo_url.rstrip('/').split('/')[-1]\n",
    "    if repo_name.endswith('.git'):\n",
    "        repo_name = repo_name[:-4]\n",
    "    print(f\"Repository name: {repo_name}\")\n",
    "\n",
    "    repo_path = \"/Users/nikolajworsoelarsen/Desktop/CSKandidat/Thesis/arch-reconstruct-ai/experiments/tool-calling/repositories/\"+repo_name\n",
    "    os.chdir(repo_path)\n",
    "\n",
    "    config_path = \"archlens.json\"\n",
    "    with open(config_path, 'w') as file:\n",
    "        json.dump(arch.__dict__, file)\n",
    "    \n",
    "    return \"Wrote to config file\"\n",
    "\n",
    "write_archLens_config_file({\"repo_url\": \"https://github.com/zeeguu/api.git\", \"arch\": archlensObject})\n",
    "\n",
    "#doesn't work yet\n",
    "run_archLens('https://github.com/zeeguu/api.git')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e4507a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository name: api\n",
      "{\n",
      "    \"$schema\": \"https://raw.githubusercontent.com/archlens/ArchLens/master/src/config.schema.json\",\n",
      "    \"name\": \"-\",\n",
      "    \"rootFolder\": \"zeeguu\",\n",
      "    \"github\": {\n",
      "        \"url\": \"https://github.com/zeeguu/api\",\n",
      "        \"branch\": \"master\"\n",
      "    },\n",
      "    \"saveLocation\": \"./diagrams/\",\n",
      "    \"views\": {\n",
      "        \"top-level-view-depth-1\": {\n",
      "            \"packages\": [\n",
      "                {\n",
      "                    \"path\": \"*\",\n",
      "                    \"depth\": 1\n",
      "                }\n",
      "            ]\n",
      "        }\n",
      "    }\n",
      "}\n",
      "Repository name: api\n",
      "{\n",
      "    \"$schema\": \"https://raw.githubusercontent.com/archlens/ArchLens/master/src/config.schema.json\",\n",
      "    \"name\": \"-\",\n",
      "    \"rootFolder\": \"zeeguu\",\n",
      "    \"github\": {\n",
      "        \"url\": \"https://github.com/zeeguu/api\",\n",
      "        \"branch\": \"master\"\n",
      "    },\n",
      "    \"saveLocation\": \"./diagrams/\",\n",
      "    \"views\": {\n",
      "        \"top-level-view-depth-1\": {\n",
      "            \"packages\": [\n",
      "                {\n",
      "                    \"path\": \"*\",\n",
      "                    \"depth\": 1\n",
      "                }\n",
      "            ]\n",
      "        }\n",
      "    }\n",
      "}\n",
      "Repository name: api\n",
      "{\n",
      "    \"$schema\": \"https://raw.githubusercontent.com/archlens/ArchLens/master/src/config.schema.json\",\n",
      "    \"name\": \"-\",\n",
      "    \"rootFolder\": \"zeeguu\",\n",
      "    \"github\": {\n",
      "        \"url\": \"https://github.com/zeeguu/api\",\n",
      "        \"branch\": \"master\"\n",
      "    },\n",
      "    \"saveLocation\": \"./diagrams/\",\n",
      "    \"views\": {\n",
      "        \"top-level-view-depth-1\": {\n",
      "            \"packages\": [\n",
      "                {\n",
      "                    \"path\": \"*\",\n",
      "                    \"depth\": 1\n",
      "                }\n",
      "            ]\n",
      "        }\n",
      "    }\n",
      "}\n",
      "[HumanMessage(content='Can you read the content of the archlens configuration file of https://github.com/zeeguu/api.git', additional_kwargs={}, response_metadata={}, id='d4ac035f-f8c0-479e-bfdb-280a92edbb2f'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_S61IQVhNwdFOkFwO5kFT8ZC3', 'function': {'arguments': '{\"repo_url\":\"https://github.com/zeeguu/api.git\"}', 'name': 'read_archLens_config_file'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 676, 'prompt_tokens': 360, 'total_tokens': 1036, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 640, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CNdGMLbFNUUXBkMc0TyRqzYxYNhvE', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--6a765037-db63-4543-9830-39e000a9b47a-0', tool_calls=[{'name': 'read_archLens_config_file', 'args': {'repo_url': 'https://github.com/zeeguu/api.git'}, 'id': 'call_S61IQVhNwdFOkFwO5kFT8ZC3', 'type': 'tool_call'}], usage_metadata={'input_tokens': 360, 'output_tokens': 676, 'total_tokens': 1036, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 640}}), ToolMessage(content='Modified archLens configuration', name='read_archLens_config_file', id='dfc0adf8-10d0-4533-91e6-1b70a4346f17', tool_call_id='call_S61IQVhNwdFOkFwO5kFT8ZC3'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_DkXHMhvo0rN0XADkvKDGQCYK', 'function': {'arguments': '{\"repo_url\":\"https://github.com/zeeguu/api.git\"}', 'name': 'read_archLens_config_file'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 548, 'prompt_tokens': 408, 'total_tokens': 956, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 512, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CNdGSu4aEIf9lLfW0ZknK1Id8jYt6', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--dbf02b3b-4a13-448a-ae9b-643eb9b2f0b9-0', tool_calls=[{'name': 'read_archLens_config_file', 'args': {'repo_url': 'https://github.com/zeeguu/api.git'}, 'id': 'call_DkXHMhvo0rN0XADkvKDGQCYK', 'type': 'tool_call'}], usage_metadata={'input_tokens': 408, 'output_tokens': 548, 'total_tokens': 956, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 512}}), ToolMessage(content='Modified archLens configuration', name='read_archLens_config_file', id='8cae21a2-32b3-4497-9fab-8fe541c91e7c', tool_call_id='call_DkXHMhvo0rN0XADkvKDGQCYK'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_dn5YjETtQy6qWXW5YxNrzyX8', 'function': {'arguments': '{\"repo_url\":\"https://github.com/zeeguu/api.git\",\"dest\":\"zeeguu_api\",\"branch\":\"\",\"overwrite\":true}', 'name': 'git_clone'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 622, 'prompt_tokens': 456, 'total_tokens': 1078, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 576, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CNdGZa7uLwwHGW99XDe6viAl2BYcr', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--05fe27f8-585a-4cfe-8608-fc0c30131c8e-0', tool_calls=[{'name': 'git_clone', 'args': {'repo_url': 'https://github.com/zeeguu/api.git', 'dest': 'zeeguu_api', 'branch': '', 'overwrite': True}, 'id': 'call_dn5YjETtQy6qWXW5YxNrzyX8', 'type': 'tool_call'}], usage_metadata={'input_tokens': 456, 'output_tokens': 622, 'total_tokens': 1078, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 576}}), ToolMessage(content='{\"success\": true, \"dest\": \"/Users/nikolajworsoelarsen/Desktop/CSKandidat/Thesis/arch-reconstruct-ai/experiments/tool-calling/repositories/api/repositories/zeeguu_api\", \"branch\": \"master\", \"error\": null}', name='git_clone', id='724dcc73-cd77-4167-ab5d-bd7fcd4d5660', tool_call_id='call_dn5YjETtQy6qWXW5YxNrzyX8'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_PgMtpD0LkNZihnlmWpDrj81n', 'function': {'arguments': '{\"repo_url\":\"https://github.com/zeeguu/api.git\"}', 'name': 'read_archLens_config_file'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 548, 'prompt_tokens': 567, 'total_tokens': 1115, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 512, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CNdGkvDlad4sFyx8z3SJ0sGgoo0Jj', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--bd1ffc46-e96d-4526-b61c-2f80953ccadf-0', tool_calls=[{'name': 'read_archLens_config_file', 'args': {'repo_url': 'https://github.com/zeeguu/api.git'}, 'id': 'call_PgMtpD0LkNZihnlmWpDrj81n', 'type': 'tool_call'}], usage_metadata={'input_tokens': 567, 'output_tokens': 548, 'total_tokens': 1115, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 512}}), ToolMessage(content='Modified archLens configuration', name='read_archLens_config_file', id='8efa8013-5373-4949-a5b3-249a91a4de83', tool_call_id='call_PgMtpD0LkNZihnlmWpDrj81n'), AIMessage(content='I tried to read the archLens configuration for the repository at https://github.com/zeeguu/api.git, but the tool returned a non-content message (\"Modified archLens configuration\") instead of the file contents.\\n\\nWhat I have done:\\n- Cloned the repo to a local workspace: \\n  /Users/nikolajworsoelarsen/Desktop/CSKandidat/Thesis/arch-reconstruct-ai/experiments/tool-calling/repositories/api/repositories/zeeguu_api\\n- The archLens config file, archlens.json, should live at the repo root of that clone. The expected path is:\\n  /Users/.../zeeguu_api/archlens.json (within the clone path above, i.e., repositories/zeeguu_api/archlens.json)\\n\\nCurrent status:\\n- The archLens config read operation keeps returning \"Modified archLens configuration\" instead of the file content. This appears to be an issue with the read_archLens_config_file tool in this environment rather than with the repo itself.\\n\\nHow would you like to proceed?\\n- I can try reading the archlens.json content again (in case the tool hiccups).\\n- If you’re comfortable, I can attempt to fetch the raw content via an alternative method (e.g., GitHub raw URL) if you authorize me to access the web.\\n- Or, if you can provide the content of archlens.json here, I can proceed with analyzing and reconstructing the architecture from it.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 2741, 'prompt_tokens': 615, 'total_tokens': 3356, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 2432, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CNdGqno3HKvKsYue67j8qbTA3Klrq', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--b254d6fc-cdf7-4b09-ad37-8cf5641d4373-0', usage_metadata={'input_tokens': 615, 'output_tokens': 2741, 'total_tokens': 3356, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 2432}})]\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "agent = create_agent(\n",
    "    \"openai:gpt-5-nano\",\n",
    "    tools=[git_clone_tool, init_archLens, run_archLens, read_archLens_config_file],\n",
    "    prompt=\"Act as an assistant, that does architectural reconstruction of software repositories. Archlens is a tool which can be used for python repositories\",\n",
    ")\n",
    "\n",
    "#result = agent.invoke({\"messages\": [HumanMessage(\"Can you clone the following github repository: https://github.com/simonskodt/arch-reconstruct-ai, feel free to overwrite if a clone already exists, \")]})\n",
    "result = agent.invoke({\"messages\": [HumanMessage(\"Can you read the content of the archlens configuration file of https://github.com/zeeguu/api.git\")]})\n",
    "print(result.get(\"messages\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff4be9f",
   "metadata": {},
   "source": [
    "#### Add Github MCP server based on url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "059673ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'experiments'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict, Any\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tool\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexperiments\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmcp_client_factory\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_mcp_config, save_mcp_config, create_mcp_client_from_config\n\u001b[32m      6\u001b[39m \u001b[38;5;129m@tool\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33madd_mcp_server\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34madd_mcp_server_tool\u001b[39m(\n\u001b[32m      8\u001b[39m     name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m      9\u001b[39m     url: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m     10\u001b[39m     transport: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mstreamable_http\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     11\u001b[39m ) -> Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m     12\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[33;03m    Add a new MCP server to the configuration.\u001b[39;00m\n\u001b[32m     14\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     24\u001b[39m \u001b[33;03m        a new agent or tool instance has to be  \u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'experiments'"
     ]
    }
   ],
   "source": [
    "from typing import Dict, Any\n",
    "from langchain.tools import tool\n",
    "from experiments.utils.mcp_client_factory import load_mcp_config, save_mcp_config, create_mcp_client_from_config\n",
    "\n",
    "\n",
    "@tool(\"add_mcp_server\")\n",
    "def add_mcp_server_tool(\n",
    "    name: str,\n",
    "    url: str,\n",
    "    transport: str = \"streamable_http\",\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Add a new MCP server to the configuration.\n",
    "    \n",
    "    Args:\n",
    "        name: Name identifier for the MCP server\n",
    "        url: URL of the MCP server\n",
    "        transport: Transport type (default: \"streamable_http\")\n",
    "    Returns:\n",
    "        Dict with success status and current config\n",
    "\n",
    "    Note: \n",
    "        MCP tools accessed via clients are not hot reloaded or dynamically  updated,\n",
    "        a new agent or tool instance has to be  \n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load existing config\n",
    "        config = load_mcp_config()\n",
    "        \n",
    "        # Add new server\n",
    "        config[name] = {\n",
    "            \"url\": url,\n",
    "            \"transport\": transport\n",
    "        }\n",
    "    \n",
    "        save_mcp_config(config)\n",
    "        \n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"message\": f\"Added MCP server '{name}'\",\n",
    "            \"config\": config\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"error\": str(e),\n",
    "            \"config\": {}\n",
    "        }\n",
    "    \n",
    "@tool(\"add_github_repository_as_mcp_server\")\n",
    "def add_github_repository_as_mcp_tool(repo_url: str, server_name: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Add a GitHub repository as an MCP server using gitmcp.io.\n",
    "    \n",
    "    Args:\n",
    "        repo_url: GitHub repository URL (e.g., https://github.com/owner/repo)\n",
    "        server_name: Name identifier for the MCP server\n",
    "    Returns:\n",
    "        Dict with success status and current config\n",
    "    \"\"\"\n",
    "    # Extract the repository path from the GitHub URL\n",
    "    if \"github.com/\" in repo_url:\n",
    "        # Extract everything after github.com/\n",
    "        repo_path = repo_url.split(\"github.com/\", 1)[1]\n",
    "        # Remove .git suffix if present\n",
    "        if repo_path.endswith(\".git\"):\n",
    "            repo_path = repo_path[:-4]\n",
    "        gitmcp_url = f\"https://gitmcp.io/{repo_path}\"\n",
    "    else:\n",
    "        raise ValueError(\"Invalid GitHub repository URL\")\n",
    "    \n",
    "    tool_input = {\n",
    "        \"name\": server_name,\n",
    "        \"url\": gitmcp_url,\n",
    "    }\n",
    "\n",
    "    return add_mcp_server_tool.invoke(tool_input)\n",
    "\n",
    "    \n",
    "\n",
    "@tool(\"remove_mcp_server\")\n",
    "def remove_mcp_server_tool(\n",
    "    name: str,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Remove an MCP server from the configuration.\n",
    "    \n",
    "    Args:\n",
    "        name: Name identifier of the MCP server to remove\n",
    "    Returns:\n",
    "        Dict with success status and current config\n",
    "\n",
    "    Note: \n",
    "        MCP tools accessed via clients are not hot reloaded or dynamically  updated,\n",
    "        a new agent or tool instance has to be \n",
    "    \"\"\"\n",
    "    try:\n",
    "        config = load_mcp_config()\n",
    "        \n",
    "        if name not in config:\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": f\"MCP server '{name}' not found\",\n",
    "                \"config\": config\n",
    "            }\n",
    "        \n",
    "        del config[name]\n",
    "        save_mcp_config(config)\n",
    "        \n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"message\": f\"Removed MCP server '{name}'\",\n",
    "            \"config\": config\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"error\": str(e),\n",
    "            \"config\": {}\n",
    "        }\n",
    "\n",
    "@tool(\"list_mcp_servers\")\n",
    "def list_mcp_servers() -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    List all configured MCP servers.\n",
    "    \n",
    "    Returns:\n",
    "        Dict with success status and list of servers\n",
    "    \"\"\"\n",
    "    try:\n",
    "        config = load_mcp_config()\n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"servers\": list(config.keys()),\n",
    "            \"config\": config\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"error\": str(e),\n",
    "            \"config\": {}\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9af334f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_iqNmvENZzhZ7Wh3kntQPXqkJ', 'function': {'arguments': '{\"repo_url\":\"https://github.com/simonskodt/arch-reconstruct-ai\",\"dest\":\"arch-reconstruct-ai\",\"branch\":null,\"overwrite\":false}', 'name': 'git_clone'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 308, 'prompt_tokens': 511, 'total_tokens': 819, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 256, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CLo4ayGmdBLSAkgAUugCxyrMtnlJ7', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--277e2183-d669-49fd-844c-d2a1f3f364b6-0', tool_calls=[{'name': 'git_clone', 'args': {'repo_url': 'https://github.com/simonskodt/arch-reconstruct-ai', 'dest': 'arch-reconstruct-ai', 'branch': None, 'overwrite': False}, 'id': 'call_iqNmvENZzhZ7Wh3kntQPXqkJ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 511, 'output_tokens': 308, 'total_tokens': 819, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 256}})]}}\n",
      "{'tools': {'messages': [ToolMessage(content='{\"success\": true, \"dest\": \"/Users/thomas/Desktop/arch-reconstruct-ai/experiments/tool-calling/repositories/arch-reconstruct-ai\", \"branch\": \"main\", \"error\": null}', name='git_clone', id='850b5a5c-b43c-4d8d-afa8-0fa1209ba2ec', tool_call_id='call_iqNmvENZzhZ7Wh3kntQPXqkJ')]}}\n",
      "{'agent': {'messages': [AIMessage(content='Cloning complete.\\n\\n- Destination: /Users/thomas/Desktop/arch-reconstruct-ai/experiments/tool-calling/repositories/arch-reconstruct-ai\\n- Branch checked out: main\\n- Status: success (no errors)\\n\\nWould you like me to do any of the following?\\n- List the top-level files and folders to get an overview\\n- Open and summarize the README and/or important docs\\n- Set up a virtual environment and install dependencies\\n- Run a quick check or a sample script from the repo\\n- Inspect specific parts (e.g., notebooks, experiments, or modules)\\n\\nTell me what you want to explore next.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 905, 'prompt_tokens': 611, 'total_tokens': 1516, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 768, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CLo4erMPAnvcfbisGZ7Ny38HAinfV', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--e90b2989-8340-410d-b832-9602c985684f-0', usage_metadata={'input_tokens': 611, 'output_tokens': 905, 'total_tokens': 1516, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 768}})]}}\n",
      "{'messages': [HumanMessage(content='Can you list the MCP servers available', additional_kwargs={}, response_metadata={}, id='69a97777-868b-45c7-adc4-1c65e5b0d72a'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_lckmEivf6jSR4N2V2m5J54ez', 'function': {'arguments': '{}', 'name': 'list_mcp_servers'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 85, 'prompt_tokens': 497, 'total_tokens': 582, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 64, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CLo4o0yiUHThct7kO0xUPvkTO4gml', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--b4046b50-80f7-491c-9a3f-2b4b8edc2b81-0', tool_calls=[{'name': 'list_mcp_servers', 'args': {}, 'id': 'call_lckmEivf6jSR4N2V2m5J54ez', 'type': 'tool_call'}], usage_metadata={'input_tokens': 497, 'output_tokens': 85, 'total_tokens': 582, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 64}}), ToolMessage(content='{\"success\": true, \"servers\": [], \"config\": {}}', name='list_mcp_servers', id='87874eba-0846-46ba-b618-8abf1e1cb360', tool_call_id='call_lckmEivf6jSR4N2V2m5J54ez'), AIMessage(content='Currently there are no MCP servers configured.\\n\\nWhat would you like to do next? Options:\\n- Add a new MCP server: provide name and URL (and optional transport; default is streamable_http)\\n  - Example: add_mcp_server with { name: \"my-server\", url: \"https://example.com/mcp\" }\\n- Link a GitHub repository as an MCP server: provide repo_url and server_name\\n  - Example: add_github_repository_as_mcp_server with { repo_url: \"https://github.com/owner/repo\", server_name: \"repo-mcp\" }\\n- After adding, I can list again to confirm.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 461, 'prompt_tokens': 539, 'total_tokens': 1000, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 320, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CLo4uGahDChxbonNdp71CKUhZQQiI', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--e31ef77c-796b-41cb-b5f3-0c7330ce52cb-0', usage_metadata={'input_tokens': 539, 'output_tokens': 461, 'total_tokens': 1000, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 320}})]}\n",
      "{'messages': [HumanMessage(content='Can you take the following github repository: https://github.com/simonskodt/arch-reconstruct-ai, and make it into a MCP server', additional_kwargs={}, response_metadata={}, id='4fc9b395-0112-4f98-b252-fb5ea7bcf6bd'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_agCCfhyUkMoE5nYNloudJWdR', 'function': {'arguments': '{\"repo_url\":\"https://github.com/simonskodt/arch-reconstruct-ai\",\"server_name\":\"arch-reconstruct-ai-mcp\"}', 'name': 'add_github_repository_as_mcp_server'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 949, 'prompt_tokens': 520, 'total_tokens': 1469, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 896, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CLo4yYhnw5r3O7R8yblHiHJBdBM0M', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--d2179dfb-2a9e-4a76-955e-5ab9cc88cc13-0', tool_calls=[{'name': 'add_github_repository_as_mcp_server', 'args': {'repo_url': 'https://github.com/simonskodt/arch-reconstruct-ai', 'server_name': 'arch-reconstruct-ai-mcp'}, 'id': 'call_agCCfhyUkMoE5nYNloudJWdR', 'type': 'tool_call'}], usage_metadata={'input_tokens': 520, 'output_tokens': 949, 'total_tokens': 1469, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 896}}), ToolMessage(content='{\"success\": true, \"message\": \"Added MCP server \\'arch-reconstruct-ai-mcp\\'\", \"config\": {\"arch-reconstruct-ai-mcp\": {\"url\": \"https://gitmcp.io/simonskodt/arch-reconstruct-ai\", \"transport\": \"streamable_http\"}}}', name='add_github_repository_as_mcp_server', id='3a7289fd-15ec-461d-a350-2768781edb85', tool_call_id='call_agCCfhyUkMoE5nYNloudJWdR'), AIMessage(content='All set. I’ve turned the repository into an MCP server.\\n\\nWhat I did\\n- Added MCP server for the repo: https://github.com/simonskodt/arch-reconstruct-ai\\n- Server name: arch-reconstruct-ai-mcp\\n- MCP URL: https://gitmcp.io/simonskodt/arch-reconstruct-ai\\n- Transport: streamable_http\\n\\nCurrent config (high level)\\n- arch-reconstruct-ai-mcp\\n  - url: https://gitmcp.io/simonskodt/arch-reconstruct-ai\\n  - transport: streamable_http\\n\\nNext steps (optional)\\n- Verify connectivity: open https://gitmcp.io/simonskodt/arch-reconstruct-ai in a browser or use an MCP client to test.\\n- List all configured MCP servers if you want to see others: I can run a list for you.\\n- Clone the repository locally for testing in the MCP environment:\\n  - If you want, I can clone it into ./repositories/arch-reconstruct-ai using GitPython.\\n- If you’d like a different server name or a different transport, I can adjust and reconfigure.\\n\\nWould you like me to clone the repository into the environment for testing, or list existing MCP servers to confirm the setup?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1292, 'prompt_tokens': 645, 'total_tokens': 1937, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 1024, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CLo55OsCNzltFyQF7DYQdiCV3QGD9', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--6cfc6363-8b43-4c9f-bafe-3e59e2c59ae3-0', usage_metadata={'input_tokens': 645, 'output_tokens': 1292, 'total_tokens': 1937, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 1024}})]}\n",
      "add_github_repository_as_mcp_server\n",
      "add_mcp_server\n",
      "remove_mcp_server\n",
      "list_mcp_servers\n",
      "git_clone\n",
      "fetch_arch_reconstruct_docs\n",
      "search_arch_docs\n",
      "search_arch_code\n",
      "fetch_generic_url_content\n",
      "{'messages': [HumanMessage(content='Can you list the MCP servers available', additional_kwargs={}, response_metadata={}, id='b6f5c0db-4a60-4bf5-b240-870f234526c5'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_KpYqAsQjbp0NUCMInAWasUUF', 'function': {'arguments': '{}', 'name': 'list_mcp_servers'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 149, 'prompt_tokens': 748, 'total_tokens': 897, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 128, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CLo5HZkZjjRBgAtCg9bxJZAGyKfei', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--5874247b-332c-41d3-a0dc-8ea2dd6d68f8-0', tool_calls=[{'name': 'list_mcp_servers', 'args': {}, 'id': 'call_KpYqAsQjbp0NUCMInAWasUUF', 'type': 'tool_call'}], usage_metadata={'input_tokens': 748, 'output_tokens': 149, 'total_tokens': 897, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 128}}), ToolMessage(content='{\"success\": true, \"servers\": [\"arch-reconstruct-ai-mcp\"], \"config\": {\"arch-reconstruct-ai-mcp\": {\"url\": \"https://gitmcp.io/simonskodt/arch-reconstruct-ai\", \"transport\": \"streamable_http\"}}}', name='list_mcp_servers', id='2ff68457-f1b6-41fe-84c3-7132762b2921', tool_call_id='call_KpYqAsQjbp0NUCMInAWasUUF'), AIMessage(content='Here are the available MCP servers:\\n\\n- arch-reconstruct-ai-mcp\\n  - URL: https://gitmcp.io/simonskodt/arch-reconstruct-ai\\n  - Transport: streamable_http\\n\\nCurrent configuration: arch-reconstruct-ai-mcp is configured with the above URL and transport.\\n\\nWould you like to add more MCP servers or modify this configuration? I can help with adding a new server or linking a GitHub repository as an MCP server.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 487, 'prompt_tokens': 833, 'total_tokens': 1320, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 384, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CLo5dXaLpwcvhHX51AEei77YtwD2u', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--3574429a-140b-4814-9421-8f36875880f4-0', usage_metadata={'input_tokens': 833, 'output_tokens': 487, 'total_tokens': 1320, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 384}})]}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "import sys\n",
    "import os\n",
    "# Add the parent directory to sys.path so 'experiments' can be imported\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..', '..')))\n",
    "from experiments.utils.agent_factory import create_agent_with_valid_tools\n",
    "\n",
    "tools = [add_github_repository_as_mcp_tool, add_mcp_server_tool, remove_mcp_server_tool, list_mcp_servers, git_clone_tool]\n",
    "\n",
    "agent = create_agent_with_valid_tools(\n",
    "    \"openai:gpt-5-nano\",\n",
    "    tools=tools,\n",
    "    prompt=\"\"\"Act as an assistant.\n",
    "                When using tools:\n",
    "                - Use tools if relevant before answering.\n",
    "            \"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "stream = agent.astream({\"messages\": [HumanMessage(\"Can you clone the github repository: https://github.com/simonskodt/arch-reconstruct-ai\")]})\n",
    "async for chunk in stream:\n",
    "    print(chunk)\n",
    "\n",
    "\n",
    "result = await agent.ainvoke({\"messages\": [HumanMessage(\"Can you list the MCP servers available\")]})\n",
    "print(result)\n",
    "\n",
    "result = await agent.ainvoke({\"messages\": [HumanMessage(\"Can you take the following github repository: https://github.com/simonskodt/arch-reconstruct-ai, and make it into a MCP server\")]})\n",
    "print(result)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "client = create_mcp_client_from_config()\n",
    "mcp_tools = await client.get_tools() \n",
    "tools += mcp_tools\n",
    "\n",
    "[print(tool.name) for tool in tools]\n",
    "\n",
    "agent = create_agent_with_valid_tools(\n",
    "    \"openai:gpt-5-nano\",\n",
    "    tools=tools, # Tools cannot be dynamically  or hot reloaded?, agent has to be recreated  \n",
    "    prompt=\"\"\"Act as an assistant.\n",
    "                When using tools:\n",
    "                - Use tools if relevant before answering.\n",
    "            \"\"\"\n",
    ")\n",
    "result = await agent.ainvoke({\"messages\": [HumanMessage(\"Can you list the MCP servers available\")]})\n",
    "print(result)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arch-reconstruct-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
